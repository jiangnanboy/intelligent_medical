# 本配置文件中的路径的根目录，根目录+其他路径=完整路径（支持相对路径，请参考：https://github.com/hankcs/HanLP/pull/254）
# Windows用户请注意，路径分隔符统一使用/
root=D:/hanlp/

# 好了，以上为唯一需要修改的部分，以下配置项按需反注释编辑。

# 核心词典路径
 CoreDictionaryPath=data/dictionary/CoreNatureDictionary.txt
# 2元语法词典路径
 BiGramDictionaryPath=data/dictionary/CoreNatureDictionary.ngram.txt
# 自定义词典路径，用;隔开多个自定义词典，空格开头表示在同一个目录，使用“文件名 词性”形式则表示这个词典的词性默认是该词性。优先级递减。
# 所有词典统一使用 UTF-8 编码，每一行代表一个单词，格式遵从[单词] [词性 A] [A 的频次] [词性 B] [B 的频次] ... 如果不填词性则表示采用词典的默认词性。
CustomDictionaryPath=data/dictionary/custom/CustomDictionary.txt; 现代汉语补充词库.txt; 全国地名大全.txt ns; 人名词典.txt; 机构名词典.txt; 三级地区.txt; 上海地名.txt ns;data/dictionary/person/nrf.txt nrf;
# 停用词词典路径
CoreStopWordDictionaryPath=data/dictionary/stopwords.txt
# 同义词词典路径
CoreSynonymDictionaryDictionaryPath=data/dictionary/synonym/CoreSynonym.txt
# 人名词典路径
PersonDictionaryPath=data/dictionary/person/nr.txt
# 人名词典转移矩阵路径
PersonDictionaryTrPath=data/dictionary/person/nr.tr.txt
# 繁简词典根目录
#tcDictionaryRoot=data/dictionary/tc
# HMM 分词模型
HMMSegmentModelPath=data/model/segment/HMMSegmentModel.bin
# 分词结果是否展示词性
ShowTermNature=true
# IO 适配器，实现 com.hankcs.hanlp.corpus.io.IIOAdapter 接口以在不同的平台（Hadoop、Redis 等）上运行 HanLP
# 默认的 IO 适配器如下，该适配器是基于普通文件系统的。
#IOAdapter=com.hankcs.hanlp.corpus.io.FileIOAdapter
# 感知机词法分析器
PerceptronCWSModelPath=data/model/perceptron/pku1998/cws.bin
PerceptronPOSModelPath=data/model/perceptron/pku1998/pos.bin
PerceptronNERModelPath=data/model/perceptron/pku1998/ner.bin
# CRF 词法分析器
CRFCWSModelPath=data/model/crf/pku199801/cws.txt
CRFPOSModelPath=data/model/crf/pku199801/pos.txt
CRFNERModelPath=data/model/crf/pku199801/ner.txt
# 更多配置项请参考 https://github.com/hankcs/HanLP/blob/master/src/main/java/com/hankcs/hanlp/HanLP.java#L59 自行添加